{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a22cdcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import os  # For working with file paths and directories\n",
    "\n",
    "# PyTorch imports for model loading and deep learning\n",
    "import torch\n",
    "import torch.nn as nn  # For defining and modifying neural network layers\n",
    "\n",
    "# Data handling and image processing\n",
    "import pandas as pd  # For reading and manipulating tabular data\n",
    "from PIL import Image  # For opening and processing image files\n",
    "\n",
    "# Image transformations and model\n",
    "from torchvision import transforms  # For preprocessing image data\n",
    "from torchvision.models import efficientnet_b0  # Pretrained EfficientNet B0 model\n",
    "\n",
    "# Machine learning utilities from scikit-learn\n",
    "from sklearn.model_selection import train_test_split  # For splitting the dataset\n",
    "from sklearn.preprocessing import OneHotEncoder  # For encoding categorical features\n",
    "from sklearn.ensemble import RandomForestRegressor  # For training a regression model\n",
    "from sklearn.metrics import mean_absolute_error  # For evaluating prediction error\n",
    "\n",
    "# Gradio for creating a web-based user interface\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71f7e219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to the Excel file containing tabular car data\n",
    "excel_path = r\"C:\\Users\\SHAHZOR AHMED\\OneDrive\\Desktop\\Major project\\A new approach\\final car details.xlsx\"\n",
    "\n",
    "# Load the Excel file into a pandas DataFrame\n",
    "df = pd.read_excel(excel_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6521d0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHAHZOR AHMED\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\SHAHZOR AHMED\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Set the device to GPU if available, else fall back to CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load EfficientNet-B0 model without pretrained ImageNet weights\n",
    "model = efficientnet_b0(pretrained=False)\n",
    "\n",
    "# Get the number of input features to the classifier layer\n",
    "num_ftrs = model.classifier[1].in_features\n",
    "\n",
    "# Replace the default classifier with a new one for 3 output classes\n",
    "# Classes: dent, no_damage, scratch\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Dropout(0.4),  # Add dropout to reduce overfitting\n",
    "    nn.Linear(num_ftrs, 3)  # Output layer for 3 damage classes\n",
    ")\n",
    "\n",
    "# Load the trained model weights\n",
    "model.load_state_dict(torch.load(\n",
    "    r\"C:\\Users\\SHAHZOR AHMED\\OneDrive\\Desktop\\Major project\\A new approach\\image_classification_dataset\\best_model.pth\",\n",
    "    map_location=device\n",
    "))\n",
    "\n",
    "# Move model to the appropriate device\n",
    "model.to(device)\n",
    "\n",
    "# Set model to evaluation mode (disables dropout, etc.)\n",
    "model.eval()\n",
    "\n",
    "# Define preprocessing steps for image classification\n",
    "damage_transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize image to 224x224 as expected by EfficientNet\n",
    "    transforms.ToTensor(),  # Convert image to PyTorch tensor\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],  # Normalize using ImageNet mean\n",
    "                         [0.229, 0.224, 0.225])  # and standard deviation\n",
    "])\n",
    "\n",
    "# Define class labels (order must match the model's training)\n",
    "class_names = ['dent', 'no_damage', 'scratch']\n",
    "\n",
    "# Path to the folder containing raw vehicle images\n",
    "image_folder = r\"C:\\Users\\SHAHZOR AHMED\\OneDrive\\Desktop\\Major project\\phase 1\\Images Dataset\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9b6c06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function attempts to resolve the full path to an image file\n",
    "# by checking common image file extensions.\n",
    "def get_image_path(image_id):\n",
    "    for ext in [\".jpg\", \".png\", \".jpeg\"]:\n",
    "        # Construct the full file path using each extension\n",
    "        candidate = os.path.join(image_folder, image_id + ext)\n",
    "        \n",
    "        # If the file exists with the current extension, return the full path\n",
    "        if os.path.exists(candidate):\n",
    "            return candidate\n",
    "\n",
    "    # Return None if no file is found with any of the tested extensions\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70e5d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the damage class ('dent', 'scratch', or 'no_damage') for a given image ID\n",
    "def predict_damage(image_id):\n",
    "    # Get the full path of the image using its ID\n",
    "    image_path = get_image_path(image_id)\n",
    "\n",
    "    # If the image doesn't exist, log a warning and return a default value\n",
    "    if image_path is None:\n",
    "        print(f\" Image not found: {image_id}\")\n",
    "        return \"not_found\"\n",
    "\n",
    "    # Open the image and convert it to RGB format\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "\n",
    "    # Apply the same preprocessing used during model training\n",
    "    img_tensor = damage_transform(image).unsqueeze(0).to(device)\n",
    "\n",
    "    # Disable gradient computation for inference\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)  # Forward pass through EfficientNet\n",
    "        _, pred = torch.max(outputs, 1)  # Get the index of the highest score (predicted class)\n",
    "\n",
    "    # Return the corresponding damage class label\n",
    "    return class_names[pred.item()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5685109d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Damage labels and summary added and saved to:\n",
      "C:\\Users\\SHAHZOR AHMED\\OneDrive\\Desktop\\Major project\\A new approach\\final_car_details_with_damage.csv\n"
     ]
    }
   ],
   "source": [
    "# Apply the damage prediction function to each image column\n",
    "# This adds 4 new columns with the predicted damage class for each side of the car\n",
    "df[\"FrontDamage\"] = df[\"Front Image\"].apply(predict_damage)\n",
    "df[\"BackDamage\"] = df[\"Back Image\"].apply(predict_damage)\n",
    "df[\"LeftDamage\"] = df[\"Left Image\"].apply(predict_damage)\n",
    "df[\"RightDamage\"] = df[\"Right Image\"].apply(predict_damage)\n",
    "\n",
    "# Create a user-friendly damage summary for each row\n",
    "# The summary combines all 4 predicted damage labels into a readable format\n",
    "df[\"Damage Summary\"] = df.apply(lambda row: f\"\"\"\n",
    "Damage Summary:\n",
    "- Front: {row['FrontDamage'].capitalize()}\n",
    "- Back: {row['BackDamage'].capitalize()}\n",
    "- Left: {row['LeftDamage'].capitalize()}\n",
    "- Right: {row['RightDamage'].capitalize()}\n",
    "\"\"\", axis=1)\n",
    "\n",
    "# Define the output file path and save the updated DataFrame to CSV\n",
    "output_path = r\"C:\\Users\\SHAHZOR AHMED\\OneDrive\\Desktop\\Major project\\A new approach\\final_car_details_with_damage.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "# Confirm the save operation in the console\n",
    "print(\"Damage labels and summary added and saved to:\")\n",
    "print(output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f09c157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model</th>\n",
       "      <th>Year</th>\n",
       "      <th>kilometers Driven</th>\n",
       "      <th>Fuel Type</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>Price</th>\n",
       "      <th>Number of Owners</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Front Image</th>\n",
       "      <th>Back Image</th>\n",
       "      <th>Left Image</th>\n",
       "      <th>Right Image</th>\n",
       "      <th>FrontDamage</th>\n",
       "      <th>BackDamage</th>\n",
       "      <th>LeftDamage</th>\n",
       "      <th>RightDamage</th>\n",
       "      <th>Damage Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013001</td>\n",
       "      <td>Tata Motors</td>\n",
       "      <td>Nexon</td>\n",
       "      <td>2017</td>\n",
       "      <td>30000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>650000</td>\n",
       "      <td>1</td>\n",
       "      <td>Red</td>\n",
       "      <td>2013001_1</td>\n",
       "      <td>2013001_2</td>\n",
       "      <td>2013001_3</td>\n",
       "      <td>2013001_4</td>\n",
       "      <td>no_damage</td>\n",
       "      <td>no_damage</td>\n",
       "      <td>no_damage</td>\n",
       "      <td>no_damage</td>\n",
       "      <td>\\nDamage Summary:\\n- Front: No_damage\\n- Back:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013002</td>\n",
       "      <td>Tata Motors</td>\n",
       "      <td>Nexon</td>\n",
       "      <td>2018</td>\n",
       "      <td>79000</td>\n",
       "      <td>Diesel</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>799000</td>\n",
       "      <td>1</td>\n",
       "      <td>Red</td>\n",
       "      <td>2013002_1</td>\n",
       "      <td>2013002_2</td>\n",
       "      <td>2013002_3</td>\n",
       "      <td>2013002_4</td>\n",
       "      <td>no_damage</td>\n",
       "      <td>dent</td>\n",
       "      <td>dent</td>\n",
       "      <td>dent</td>\n",
       "      <td>\\nDamage Summary:\\n- Front: No_damage\\n- Back:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013003</td>\n",
       "      <td>Tata Motors</td>\n",
       "      <td>Nexon</td>\n",
       "      <td>2017</td>\n",
       "      <td>49317</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Automatic</td>\n",
       "      <td>800000</td>\n",
       "      <td>1</td>\n",
       "      <td>Blue</td>\n",
       "      <td>2013003_1</td>\n",
       "      <td>2013003_2</td>\n",
       "      <td>2013003_3</td>\n",
       "      <td>2013003_4</td>\n",
       "      <td>scratch</td>\n",
       "      <td>dent</td>\n",
       "      <td>no_damage</td>\n",
       "      <td>no_damage</td>\n",
       "      <td>\\nDamage Summary:\\n- Front: Scratch\\n- Back: D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013004</td>\n",
       "      <td>Tata Motors</td>\n",
       "      <td>Nexon</td>\n",
       "      <td>2018</td>\n",
       "      <td>100000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>790000</td>\n",
       "      <td>1</td>\n",
       "      <td>White</td>\n",
       "      <td>2013004_1</td>\n",
       "      <td>2013004_2</td>\n",
       "      <td>2013004_3</td>\n",
       "      <td>2013004_4</td>\n",
       "      <td>no_damage</td>\n",
       "      <td>dent</td>\n",
       "      <td>scratch</td>\n",
       "      <td>no_damage</td>\n",
       "      <td>\\nDamage Summary:\\n- Front: No_damage\\n- Back:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013005</td>\n",
       "      <td>Tata Motors</td>\n",
       "      <td>Nexon</td>\n",
       "      <td>2018</td>\n",
       "      <td>76000</td>\n",
       "      <td>Petrol</td>\n",
       "      <td>Manual</td>\n",
       "      <td>650000</td>\n",
       "      <td>1</td>\n",
       "      <td>Black</td>\n",
       "      <td>2013005_1</td>\n",
       "      <td>2013005_2</td>\n",
       "      <td>2013005_3</td>\n",
       "      <td>2013005_4</td>\n",
       "      <td>scratch</td>\n",
       "      <td>no_damage</td>\n",
       "      <td>dent</td>\n",
       "      <td>dent</td>\n",
       "      <td>\\nDamage Summary:\\n- Front: Scratch\\n- Back: N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID        Brand  Model  Year  kilometers Driven Fuel Type  \\\n",
       "0  2013001  Tata Motors  Nexon  2017              30000    Petrol   \n",
       "1  2013002  Tata Motors  Nexon  2018              79000    Diesel   \n",
       "2  2013003  Tata Motors  Nexon  2017              49317    Petrol   \n",
       "3  2013004  Tata Motors  Nexon  2018             100000    Petrol   \n",
       "4  2013005  Tata Motors  Nexon  2018              76000    Petrol   \n",
       "\n",
       "  Transmission   Price  Number of Owners Colour Front Image Back Image  \\\n",
       "0       Manual  650000                 1    Red   2013001_1  2013001_2   \n",
       "1    Automatic  799000                 1    Red   2013002_1  2013002_2   \n",
       "2    Automatic  800000                 1   Blue   2013003_1  2013003_2   \n",
       "3       Manual  790000                 1  White   2013004_1  2013004_2   \n",
       "4       Manual  650000                 1  Black   2013005_1  2013005_2   \n",
       "\n",
       "  Left Image Right Image FrontDamage BackDamage LeftDamage RightDamage  \\\n",
       "0  2013001_3   2013001_4   no_damage  no_damage  no_damage   no_damage   \n",
       "1  2013002_3   2013002_4   no_damage       dent       dent        dent   \n",
       "2  2013003_3   2013003_4     scratch       dent  no_damage   no_damage   \n",
       "3  2013004_3   2013004_4   no_damage       dent    scratch   no_damage   \n",
       "4  2013005_3   2013005_4     scratch  no_damage       dent        dent   \n",
       "\n",
       "                                      Damage Summary  \n",
       "0  \\nDamage Summary:\\n- Front: No_damage\\n- Back:...  \n",
       "1  \\nDamage Summary:\\n- Front: No_damage\\n- Back:...  \n",
       "2  \\nDamage Summary:\\n- Front: Scratch\\n- Back: D...  \n",
       "3  \\nDamage Summary:\\n- Front: No_damage\\n- Back:...  \n",
       "4  \\nDamage Summary:\\n- Front: Scratch\\n- Back: N...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the updated dataset that includes:\n",
    "# - Tabular car features\n",
    "# - Predicted damage labels for all 4 sides\n",
    "# - A human-readable damage summary\n",
    "df = pd.read_csv(r\"C:\\Users\\SHAHZOR AHMED\\OneDrive\\Desktop\\Major project\\A new approach\\final_car_details_with_damage.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset to verify its structure and content\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2032f423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en_IN'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries for model training and evaluation\n",
    "\n",
    "import pandas as pd  # For data manipulation and loading\n",
    "import joblib  # For saving and loading trained models and encoders\n",
    "\n",
    "# Scikit-learn utilities for training and preprocessing\n",
    "from sklearn.model_selection import train_test_split  # For splitting data into train and validation sets\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler  # For encoding categorical features and normalizing numerical ones\n",
    "from sklearn.metrics import mean_absolute_error  # For evaluating model performance\n",
    "\n",
    "# XGBoost library for training a high-performance regression model\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# RandomizedSearchCV for hyperparameter tuning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Locale for formatting currency output\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'en_IN')  # Set locale to Indian format for currency display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89fc87b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset that includes vehicle details and predicted damage labels\n",
    "df = pd.read_csv(r\"C:\\Users\\SHAHZOR AHMED\\OneDrive\\Desktop\\Major project\\A new approach\\final_car_details_with_damage.csv\")\n",
    "\n",
    "# Create a copy of the dataset to use for model training\n",
    "# This helps preserve the original dataset for reference or other use\n",
    "df_model = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c806d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the 'kilometers Driven' feature using standard scaling\n",
    "# This scales the values to have a mean of 0 and standard deviation of 1,\n",
    "# which helps many machine learning models perform better\n",
    "scaler = StandardScaler()\n",
    "df_model['kilometers Driven'] = scaler.fit_transform(df_model[['kilometers Driven']])\n",
    "\n",
    "# Convert categorical damage labels into numerical severity scores\n",
    "# 'no_damage' = 0, 'scratch' = 1, 'dent' = 2\n",
    "# This allows the model to interpret the damage information as ordinal values\n",
    "damage_map = {'no_damage': 0, 'scratch': 1, 'dent': 2}\n",
    "for col in ['FrontDamage', 'BackDamage', 'LeftDamage', 'RightDamage']:\n",
    "    df_model[col] = df_model[col].map(damage_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed3afb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input features to be used for price prediction\n",
    "# Includes tabular features and numerically encoded damage scores\n",
    "features = [\n",
    "    'Brand', 'Model', 'Year', 'kilometers Driven', 'Fuel Type',\n",
    "    'Transmission', 'Number of Owners', 'Colour',\n",
    "    'FrontDamage', 'BackDamage', 'LeftDamage', 'RightDamage'\n",
    "]\n",
    "\n",
    "# Separate the input features (X) and the target variable (y)\n",
    "X = df_model[features]\n",
    "y = df_model['Price']  # The resale price is the prediction target\n",
    "\n",
    "# One-hot encode categorical features (e.g., Brand, Model, Fuel Type)\n",
    "# This transforms them into binary vectors suitable for model input\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95066803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "# Define a parameter grid for hyperparameter tuning of the XGBoost regressor\n",
    "# These parameters control model complexity, learning speed, and sampling strategy\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],          # Number of trees in the ensemble\n",
    "    'learning_rate': [0.01, 0.05, 0.1],       # Step size shrinkage used in updates\n",
    "    'max_depth': [3, 5, 7],                   # Maximum depth of each tree\n",
    "    'subsample': [0.6, 0.8, 1.0],             # Fraction of data used for each tree\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0]       # Fraction of features used per tree\n",
    "}\n",
    "\n",
    "# Initialize the XGBoost Regressor with a fixed objective and random seed\n",
    "xgb = XGBRegressor(objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Perform randomized search over the parameter grid\n",
    "# - n_iter: number of random parameter combinations to try\n",
    "# - scoring: use negative MAE as the optimization metric\n",
    "# - cv: use 3-fold cross-validation to evaluate each combination\n",
    "# - n_jobs=-1: use all available CPU cores\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=20,\n",
    "    scoring='neg_mean_absolute_error',\n",
    "    cv=3,\n",
    "    verbose=1,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Train the model and find the best parameter combination\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Extract the best performing model from the search\n",
    "best_model = random_search.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f905ccfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Validation MAE: ₹1,39,548.09\n"
     ]
    }
   ],
   "source": [
    "# Use the best trained XGBoost model to predict prices on the validation set\n",
    "y_pred = best_model.predict(X_val)\n",
    "\n",
    "# Calculate the Mean Absolute Error (MAE) between predicted and actual prices\n",
    "mae = mean_absolute_error(y_val, y_pred)\n",
    "\n",
    "# Display the MAE in Indian currency format for better interpretability\n",
    "print(\"XGBoost Validation MAE:\", locale.format_string(\"₹%.2f\", mae, grouping=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8bc540d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler_km.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the trained XGBoost model to a file for later use (e.g., in the web app)\n",
    "joblib.dump(best_model, \"price_model_xgb.pkl\")\n",
    "\n",
    "# Save the one-hot encoder used for categorical feature transformation\n",
    "joblib.dump(encoder, \"encoder_xgb.pkl\")\n",
    "\n",
    "# Save the scaler used to normalize the 'kilometers Driven' feature\n",
    "joblib.dump(scaler, \"scaler_km.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9006e7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: ₹1,39,548.09\n",
      "RMSE: ₹2,06,563.75\n",
      "R² Score: 0.9607\n"
     ]
    }
   ],
   "source": [
    "# Import additional evaluation metrics\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Compute Mean Squared Error (MSE)\n",
    "mse = mean_squared_error(y_val, y_pred)\n",
    "\n",
    "# Compute Root Mean Squared Error (RMSE) by taking the square root of MSE\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "# Compute R² Score (coefficient of determination) to measure model fit\n",
    "r2 = r2_score(y_val, y_pred)\n",
    "\n",
    "# Display evaluation metrics using Indian currency formatting\n",
    "print(\"MAE:\", locale.format_string(\"₹%.2f\", mae, grouping=True))   # Already computed earlier\n",
    "print(\"RMSE:\", locale.format_string(\"₹%.2f\", rmse, grouping=True))  # Measures typical prediction error\n",
    "print(f\"R² Score: {r2:.4f}\")  # Indicates how well the model explains variance (closer to 1 is better)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
